{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "firstnotebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPc97O4f/9/VUKU5hviZ6rp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharathbantwal/hello-world/blob/master/firstnotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qnl6Mt8Z3r9",
        "outputId": "583acc6c-b171-4d24-bd3f-8f5f3923d180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5498, 0.7914],\n",
            "        [0.9746, 0.6417]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.7137, 0.6785, 0.3075],\n",
            "        [0.1849, 0.1346, 0.2881]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Sleeping\n",
            "Done Sleeping\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n",
            "tensor @ tensor.T \n",
            " tensor([[1.3699, 1.0345, 1.1117],\n",
            "        [1.0345, 1.8209, 1.4321],\n",
            "        [1.1117, 1.4321, 1.5738]])\n",
            "tensor.matmul(tensor.T) \n",
            " tensor([[1.3699, 1.0345, 1.1117],\n",
            "        [1.0345, 1.8209, 1.4321],\n",
            "        [1.1117, 1.4321, 1.5738]]) \n",
            "\n",
            "tensor.mul(tensor) \n",
            " tensor([[0.3829, 0.0010, 0.3371, 0.6488],\n",
            "        [0.8394, 0.7316, 0.1993, 0.0505],\n",
            "        [0.7900, 0.0685, 0.7089, 0.0064]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[0.3829, 0.0010, 0.3371, 0.6488],\n",
            "        [0.8394, 0.7316, 0.1993, 0.0505],\n",
            "        [0.7900, 0.0685, 0.7089, 0.0064]])\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
        "\n",
        "\n",
        "\n",
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
        "print(\"Sleeping\")\n",
        "time.sleep(1) # sleep for a while; interrupt me!\n",
        "print(\"Done Sleeping\")\n",
        "\n",
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")\n",
        "\n",
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")\n",
        "\n",
        "\n",
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)\n",
        "print(tensor, \"\\n\")\n",
        "\n",
        "tensor.add_(5)\n",
        "print(tensor)\n",
        "\n",
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")\n",
        "\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")\n",
        "\n",
        " = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "\n",
        "\n",
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    }
  ]
}